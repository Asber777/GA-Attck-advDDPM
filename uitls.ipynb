{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import lpips\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms\n",
    "\n",
    "import torch.distributed as dist\n",
    "from pytorch_msssim import ssim\n",
    "\n",
    "os.environ['TORCH_HOME']='~/.cache/torch/'\n",
    "def reduce_tensor(tensor, n):\n",
    "    rt = tensor.clone()\n",
    "    dist.all_reduce(rt, op=dist.ReduceOp.SUM)\n",
    "    return rt\n",
    "\n",
    "from utils import MyCustomDataset, get_architecture, Input_diversity, MultiEnsemble\n",
    "from utils import CrossEntropyLoss, MarginLoss\n",
    "# from vscodearg import add_dict_to_argparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch Unrestricted Attack')\n",
    "parser.add_argument('--batch_size', type=int, default=5,metavar='N', help='batch size for attack (default: 30)')\n",
    "parser.add_argument('--attack_method', type=str, default=\"GA_TDMI_fgsm\")\n",
    "parser.add_argument('--save_path', type=str, default=\"tmp/images\")\n",
    "parser.add_argument('--threat_model', type=str, default='Linf')\n",
    "parser.add_argument('--mode', type=str, default=\"nearest\")\n",
    "parser.add_argument('--loss_fn', type=str, default=\"ce\")#ce\n",
    "parser.add_argument('--momentum', default=1.0, type=float,help='momentum, (default: 1.0)')\n",
    "parser.add_argument('--epsilon', default=20, type=float,help='perturbation, (default: 16)')\n",
    "parser.add_argument('--max_epsilon', default=20, type=float,help='perturbation, (default: 16)')\n",
    "parser.add_argument('--intervals', default=5, type=int,help='number of intervals')\n",
    "parser.add_argument('--num_steps', default=10, type=int,help='number of steps in TDMI')\n",
    "parser.add_argument('--kernel_size', default=5, type=int,help='kernel size of gaussian filter') \n",
    "parser.add_argument('--target_id', default=7, type=int,help='InceptionResnetV2 as default')\n",
    "parser.add_argument('--target_m', default=\"Engstrom2019Robustness\", type=str,help='robustbench model to be attacked')\n",
    "parser.add_argument('--source_list', default='2_3_5', type=str)\n",
    "parser.add_argument('--auxiliary_list', default='1_4_6', type=str)\n",
    "parser.add_argument('--prob', default=0.7, type=float,help='input diversity prob')\n",
    "parser.add_argument('--thres', default=0.2, type=float, help='threshold for continue attack')\n",
    "parser.add_argument('--scale', default=0.1, type=float,help='input diversity scale')\n",
    "parser.add_argument('--distributed', action='store_true',help='Use multi-processing distributed training to launch')\n",
    "parser.add_argument(\"--local_rank\", default=0, type=int, help='local rank for DistributedDataParallel')\n",
    "# add_dict_to_argparser(parser, defaults)\n",
    "\n",
    "NUM_CLASSES = 1000\n",
    "\n",
    "MODEL_NAME_DICT = {\n",
    "    0: \"vit_small_patch16_224\",\n",
    "    1: \"vit_base_patch16_224\",\n",
    "    2: \"swin_base_patch4_window7_224\",\n",
    "    3: \"swsl_resnext101_32x8d\",\n",
    "    4: \"ssl_resnext50_32x4d\",\n",
    "    5: \"swsl_resnet50\",\n",
    "    6: \"InceptionV3\",\n",
    "    7: \"InceptionResnetV2\",\n",
    "    8: \"adv_inception_v3\",\n",
    "    9: \"ens_adv_inception_resnet_v2\",\n",
    "    10: \"Resnet152-DenoiseAll\",\n",
    "    11: \"AdvResnet152\",\n",
    "    12: \"Resnext101-DenoiseAll\"\n",
    "}\n",
    "\n",
    "def init_seeds(seed=0, cuda_deterministic=True):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    # Speed-reproducibility tradeoff https://pytorch.org/docs/stable/notes/randomness.html\n",
    "    if cuda_deterministic:  # slower, more reproducible\n",
    "        cudnn.deterministic = True\n",
    "        cudnn.benchmark = False\n",
    "    else:  # faster, less reproducible\n",
    "        cudnn.deterministic = False\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "def normalize(item):\n",
    "    max = item.max()\n",
    "    min = item.min()\n",
    "    return (item - min) / (max - min)\n",
    "\n",
    "def main(args):\n",
    "\n",
    "    init_seeds(cuda_deterministic=True)\n",
    "    logger.configure(args.save_path)\n",
    "    # Target model\n",
    "    if not args.distributed or args.local_rank == 0:\n",
    "        logger.log(\"Using {} as target model!\".format(MODEL_NAME_DICT[args.target_id]))\n",
    "    if args.target_m is not None:\n",
    "        tmp_model = get_architecture(model_name=args.target_m, threat_model=args.threat_model).cuda().eval()\n",
    "    elif args.target_id is not None:\n",
    "        tmp_model = get_architecture(model_name=MODEL_NAME_DICT[args.target_id]).cuda().eval()\n",
    "    else:\n",
    "        raise ValueError(\"plz assign target_m or target_id\")\n",
    "    Target_model = Input_diversity(tmp_model, args=args, num_classes=NUM_CLASSES, prob=args.prob, mode=args.mode, diversity_scale=args.scale)\n",
    "\n",
    "    # Source model\n",
    "    source_id_list = [int(item) for item in args.source_list.split('_')]\n",
    "    if not args.distributed or args.local_rank == 0:\n",
    "        logger.log(\"Source id list: {}\".format(source_id_list))\n",
    "    \n",
    "    # Source_model_list = []\n",
    "    # for idx in source_id_list:\n",
    "    #     temp_model = get_architecture(model_name=MODEL_NAME_DICT[idx]).cuda().eval()\n",
    "    #     Source_model_list.append(temp_model)\n",
    "\n",
    "    # Source_model = MultiEnsemble(Source_model_list, args=args, num_classes=NUM_CLASSES, prob=args.prob, mode=args.mode, diversity_scale=args.scale)\n",
    "    Source_model = Target_model\n",
    "\n",
    "    # Auxiliary model\n",
    "    auxiliary_id_list = [int(item) for item in args.auxiliary_list.split('_')]\n",
    "    if not args.distributed or args.local_rank == 0:\n",
    "        logger.log(\"Auxiliary id list: {}\".format(auxiliary_id_list))\n",
    "\n",
    "    Auxiliary_model_list = []\n",
    "    for idx in auxiliary_id_list:\n",
    "        temp_model = get_architecture(model_name=MODEL_NAME_DICT[idx]).cuda().eval()\n",
    "        Auxiliary_model_list.append(temp_model)\n",
    "\n",
    "    Auxiliary_model = MultiEnsemble(Auxiliary_model_list, args=args, num_classes=NUM_CLASSES, prob=args.prob, mode=args.mode, diversity_scale=args.scale)\n",
    "\n",
    "    loader = MyCustomDataset(img_path=\"data/images\")\n",
    "    if args.distributed:\n",
    "        sampler = torch.utils.data.distributed.DistributedSampler(loader)\n",
    "    else:\n",
    "        sampler = torch.utils.data.SequentialSampler(loader)\n",
    "\n",
    "    loss_fn_alex = lpips.LPIPS(net='alex')\n",
    "    loss_fn_alex = loss_fn_alex.cuda()\n",
    "\n",
    "    attack_loader = torch.utils.data.DataLoader(dataset=loader,\n",
    "                                                batch_size=args.batch_size,\n",
    "                                                shuffle=False,\n",
    "                                                sampler=sampler, num_workers=8, pin_memory=True)\n",
    "    if not os.path.isdir(args.save_path):\n",
    "        os.makedirs(args.save_path, exist_ok=True)\n",
    "    \n",
    "    diff_path = args.save_path + \"/diff\"\n",
    "    if not os.path.isdir(diff_path):\n",
    "        os.makedirs(diff_path, exist_ok=True)\n",
    "    image_path = args.save_path + \"/image\"\n",
    "    if not os.path.isdir(image_path):\n",
    "        os.makedirs(image_path, exist_ok=True)\n",
    "\n",
    "    # save budgrt with a dict\n",
    "    img_budget = {}\n",
    "\n",
    "    natural_err_total, target_err_total = torch.tensor(0.0).cuda(), torch.tensor(0.0).cuda()\n",
    "    Lp_dis_total = torch.tensor(0.0).cuda()\n",
    "    eps_total = torch.tensor(0.0).cuda()\n",
    "    quality_level = torch.tensor(0.0).cuda()\n",
    "    lpips_total = torch.tensor(0.0).cuda()\n",
    "    ssim_total = torch.tensor(0.0).cuda()\n",
    "\n",
    "    count = 0\n",
    "    time_start = time.time()\n",
    "    if not args.distributed or args.local_rank == 0:\n",
    "        logger.log(\"Starting time counting: {}\\n\".format(time_start))\n",
    "\n",
    "    # loss_fn\n",
    "    if args.loss_fn == \"ce\":\n",
    "        loss_fn = CrossEntropyLoss()\n",
    "    elif args.loss_fn == \"margin\":\n",
    "        loss_fn = MarginLoss()\n",
    "    else:\n",
    "        raise Exception(\"invalid loss function!\")\n",
    "\n",
    "    # distance metric\n",
    "    if \"fgsm\" in args.attack_method:\n",
    "        reward_fn = lambda x: 1.0 / (x * 255.0)\n",
    "    else:\n",
    "        reward_fn = lambda x: 1.0 / (x)\n",
    "        \n",
    "    for (img, label, img_name) in attack_loader:\n",
    "        img, label = img.cuda(), label.cuda()\n",
    "        batch_szie = img.shape[0]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = Source_model(img, diversity=False)\n",
    "\n",
    "        err = (out.data.max(1)[1] != label.data).float().sum()\n",
    "        natural_err_total += err\n",
    "\n",
    "        if args.attack_method == \"TDI_fgsm\":\n",
    "            x_adv, budget = TDI_fgsm(Source_model, img.clone(), label.clone(), args, loss_fn)\n",
    "        elif args.attack_method == \"GA_TDI_fgsm\":\n",
    "            x_adv, budget = GA_TDI_fgsm(Source_model, Auxiliary_model, img.clone(), label.clone(), args, loss_fn)\n",
    "        elif args.attack_method == \"DI_fgsm\":\n",
    "            x_adv, budget = DI_fgsm(Source_model, img.clone(), label.clone(), args, loss_fn)\n",
    "        elif args.attack_method == \"GA_DI_fgsm\":\n",
    "            x_adv, budget = GA_DI_fgsm(Source_model, Auxiliary_model, img.clone(), label.clone(), args, loss_fn)\n",
    "        elif args.attack_method == \"TDMI_fgsm\":\n",
    "            x_adv, budget = TDMI_fgsm(Source_model, img.clone(), label.clone(), args, loss_fn)\n",
    "        elif args.attack_method == \"GA_TDMI_fgsm\":\n",
    "            x_adv, budget = GA_TDMI_fgsm(Source_model, Auxiliary_model, img.clone(), label.clone(), args, loss_fn)\n",
    "\n",
    "\n",
    "        elif args.attack_method == \"FSA\":\n",
    "            x_adv = Feature_Adam_Attack(Source_model, img.clone(), label.clone(), args, loss_fn, diversity=False)\n",
    "            budget = args.epsilon * torch.ones([x_adv.shape[0]])\n",
    "        elif args.attack_method == \"DI_FSA\":\n",
    "            x_adv, budget= DI_FSA(Source_model, img.clone(), label.clone(), args, loss_fn)\n",
    "        elif args.attack_method == \"GA_DI_FSA\":\n",
    "            x_adv, budget = GA_DI_FSA(Source_model, Auxiliary_model, img.clone(), label.clone(), args, loss_fn)\n",
    "        elif args.attack_method == \"DMI_FSA\":\n",
    "            x_adv, budget = DMI_FSA(Source_model, img.clone(), label.clone(), args, loss_fn)\n",
    "        elif args.attack_method == \"GA_DMI_FSA\":\n",
    "            x_adv, budget = GA_DMI_FSA(Source_model, Auxiliary_model, img.clone(), label.clone(), args, loss_fn)\n",
    "        elif args.attack_method == \"recolor\":\n",
    "            attack = ReColorAdvAttack(model=Source_model, bound=args.epsilon, num_iterations=args.num_steps)\n",
    "            x_adv = attack(img.clone(), label.clone()).detach()\n",
    "            budget = args.epsilon * torch.ones([x_adv.shape[0]])\n",
    "        else:\n",
    "            raise Exception(\"invalid attack method !\")\n",
    "\n",
    "        count += batch_szie\n",
    "\n",
    "        # Attack on Target model\n",
    "        with torch.no_grad():\n",
    "            out = Target_model(x_adv, diversity=False)\n",
    "            err_mask = (out.data.max(1)[1] != label.data)\n",
    "            err_target = err_mask.float().sum()\n",
    "            target_err_total += err_target\n",
    "        Lp_dis = torch.abs(x_adv - img).reshape(len(x_adv), -1).max(dim = -1)[0][err_mask]\n",
    "        distance_batch = budget[err_mask]\n",
    "        lpips_batch = loss_fn_alex.forward(img, x_adv, normalize=True)[err_mask]\n",
    "        ssim_batch = ssim(img, x_adv, data_range=1., size_average=False)[err_mask]\n",
    "        \n",
    "        eps_total += distance_batch.sum()\n",
    "        Lp_dis_total += Lp_dis.data.sum()\n",
    "        batch_score = reward_fn(distance_batch)\n",
    "        quality_level += batch_score.sum() \n",
    "        lpips_total += lpips_batch.sum()\n",
    "        ssim_total += ssim_batch.sum()\n",
    "        logger.log(\"Attacked: {}, Batch size: {},\\\n",
    "                Image name: {}, Nature error: {}, \\\n",
    "                Target error: {}, Target error mask: {}, \\\n",
    "                budgets: {}, Batch distance Max: {}, \\\n",
    "                Avg: {}, Avg reward: {}, Lp: {}\".format(count, batch_szie,\n",
    "                img_name, err.item(), err_target.item(), err_mask,\n",
    "                budget, distance_batch.max().item(), \n",
    "                distance_batch.mean().item(), batch_score.mean().item(), \n",
    "                Lp_dis.data.sum()))\n",
    "\n",
    "        budget_cpu = budget.detach()\n",
    "        budget_cpu[~err_mask] *= -1\n",
    "        budget_cpu = budget_cpu.cpu().numpy()\n",
    "\n",
    "        for i in range(batch_szie):\n",
    "            x_adv_cpu = x_adv[i, :, :, :].cpu()\n",
    "            torch.save(x_adv_cpu, image_path+ \"/\" + img_name[i][:-4]+'.pt')\n",
    "            img_adv = transforms.ToPILImage()(x_adv_cpu).convert('RGB')\n",
    "            img_adv.save(image_path + \"/\" + img_name[i])\n",
    "\n",
    "            x_cpu_numpy = 255.0 * img[i, :, :, :].cpu().numpy().transpose(1,2,0)\n",
    "            x_adv_numpy = 255.0 * x_adv_cpu.numpy().transpose(1,2,0)\n",
    "            save_diff = np.concatenate((x_cpu_numpy, x_adv_numpy, 255.0 * normalize(x_adv_numpy - x_cpu_numpy)))\n",
    "            save_diff = np.reshape(save_diff, newshape=[299*3, 299, 3])\n",
    "            save_diff = save_diff.astype(np.uint8)\n",
    "            Image.fromarray(save_diff, mode='RGB').save(diff_path + \"/\" + img_name[i])\n",
    "\n",
    "            # budget\n",
    "            img_budget[img_name[i]] = budget_cpu[i]\n",
    "\n",
    "\n",
    "    if args.distributed:\n",
    "        eps_total = reduce_tensor(eps_total.data, args.world_size)\n",
    "        Lp_dis_total = reduce_tensor(Lp_dis_total.data, args.world_size)\n",
    "        quality_level = reduce_tensor(quality_level.data, args.world_size)\n",
    "        natural_err_total = reduce_tensor(natural_err_total.data, args.world_size)\n",
    "        pgd_err_total = reduce_tensor(pgd_err_total.data, args.world_size)\n",
    "        target_err_total = reduce_tensor(target_err_total.data, args.world_size)\n",
    "\n",
    "        # save budget localrank-wise\n",
    "        budget_path = os.path.join(args.save_path, str(args.local_rank) + \"_rank_budget.npy\")\n",
    "        np.save(budget_path, img_budget)\n",
    "    else:\n",
    "        budget_path = os.path.join(args.save_path, \"budget.npy\")\n",
    "        np.save(budget_path, img_budget)\n",
    "\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "    time_end = time.time()\n",
    "    if not args.distributed or args.local_rank == 0:\n",
    "        logger.log('time cost', time_end-time_start, 's')\n",
    "        logger.log(\"Nature Error total: \", natural_err_total)\n",
    "        logger.log(\"Target Success total: \", target_err_total)\n",
    "        if \"fgsm\" in args.attack_method:\n",
    "            logger.log('Avg distance of successfully transferred: {}'.format((eps_total / target_err_total) * 255.0))\n",
    "        else:\n",
    "            logger.log('Avg distance of successfully transferred: {}'.format((eps_total / target_err_total)))   \n",
    "        logger.log('Avg Lp_distance: {}'.format((Lp_dis_total / target_err_total)))\n",
    "        logger.log('Avg perturbation reward: {}'.format((quality_level / target_err_total)))\n",
    "        logger.log('Avg LPIPS dis: {}'.format((lpips_total / target_err_total)))\n",
    "        logger.log('Avg SSIM dis: {}'.format((ssim_total / target_err_total)))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    opt = parser.parse_args()\n",
    "\n",
    "    if opt.distributed:\n",
    "        print(\"opt.local_rank:{}\".format(opt.local_rank))\n",
    "        torch.cuda.set_device(opt.local_rank)\n",
    "        torch.distributed.init_process_group(backend='nccl', init_method='env://')\n",
    "        opt.world_size = dist.get_world_size()\n",
    "        opt.batch_size = int(opt.batch_size / opt.world_size)\n",
    "    \n",
    "    if not opt.distributed or opt.local_rank == 0:\n",
    "        print(opt)\n",
    "\n",
    "    OUTPUT_DIR=f\"Output_Feature_APR_FGSM/Ensemble_TID_{opt.target_m}\"+\\\n",
    "        f\"_SIDLIST_{opt.source_list}_Auxiliary_id_list_{opt.auxiliary_list}\"+\\\n",
    "        f\"_{opt.attack_method}_{opt.loss_fn}_thres_{opt.thres}_intervals_{opt.intervals}\"+\\\n",
    "        f\"_steps_{opt.num_steps}_max_eps_{opt.max_epsilon}_eps_{opt.epsilon}_mu_{opt.momentum}\"+\\\n",
    "        f\"_mode_{opt.mode}_kernel_size_{opt.kernel_size}\"\n",
    "    if not os.path.isdir(OUTPUT_DIR):\n",
    "        os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    opt.save_path = OUTPUT_DIR\n",
    "    args_path = os.path.join(OUTPUT_DIR, f\"exp.json\")\n",
    "    info_json = json.dumps(vars(opt), sort_keys=False, indent=4, separators=(' ', ':'))\n",
    "    with open(args_path, 'w') as f:\n",
    "        f.write(info_json)\n",
    "    main(opt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88516cc94b965045253aac22be7e673e07faa374a8dfeab45aefc65ddf94d8b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
